{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c307e48-0c9a-4c2e-a154-dcce66e2ab1e",
   "metadata": {},
   "source": [
    "# `POMDPs.jl` Tutorial\n",
    "\n",
    "`POMDPs.jl` provides a set of structs and functions to define and solve partially observable markov decision processes. These are a class of models used to describe a rational agent making deciison under undertianty. They are useful for economic problems, expecially in conservaiton and natrual resource managment were uncertanty is pervasive. This libaray focuses on solving POMDPs with at least one continuous state variable. Continuous state POMDPs an be solved as beleif state MDPs using standard dynamic programming techniques. \n",
    "\n",
    "A beleif state MDP trackes the dynamics of the decision makers beleifs about the state and the dynamics of the system their decision will effect. The decision problem can be solved by finding a value funtion defined over the beleif state space using (more or less) standard techniques. However, the challenge comes frun the need to define the dynaics of the deciison makers beleifs. these take the form of partially observable markov process or state space models. \n",
    "\n",
    "These models are defined by a state transition function $T(x,a)  = x'$ and an observaiton model $G(yt,x,a) = d/dy P(Y < y|x,a)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52681ef-1438-4f7d-aa25-eb339603eea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JuliaPro_v1.5.4-1 1.5.4",
   "language": "julia",
   "name": "juliapro_v1.5.4-1-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
